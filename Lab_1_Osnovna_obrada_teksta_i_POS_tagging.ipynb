{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn2eP-YPAeBV"
      },
      "source": [
        "# Lab 1: Osnovna obrada teksta i označavanje vrsta riječi (POS Tagging)\n",
        "\n",
        "## Ciljevi\n",
        "Cilj ove vježbe je upoznati vas s osnovnim principima **obrade prirodnog jezika (NLP)** i praktičnim tehnikama koje se koriste za analizu tekstova. Nakon završetka vježbe trebali biste moći:\n",
        "\n",
        "- Razumjeti osnovne korake obrade teksta u NLP-u, uključujući čišćenje podataka, tokenizaciju, lematizaciju i uklanjanje stop-riječi.\n",
        "- Koristiti biblioteke `spaCy` i `NLTK` za praktičnu obradu teksta u Pythonu, uključujući prepoznavanje gramatičkih kategorija riječi.\n",
        "- Izvesti **normalizaciju teksta** kako bi podaci bili pripremljeni za analizu, što uključuje uklanjanje neželjenih znakova, pretvaranje riječi u osnovni oblik i filtriranje riječi iz bilo kojeg izvora.\n",
        "- Primijeniti **POS tagging** na uzorke tekstova i analizirati dobivene rezultate kako biste razumjeli strukturu jezika u tekstu.\n",
        "\n",
        "## Očekivani ishod\n",
        "Nakon vježbe, moći ćete:\n",
        "\n",
        "- Objasniti što znače osnovni NLP pojmovi kao što su tokenizacija, lematizacija, stemming i POS tagging, te zašto su važni u obradi jezika.\n",
        "- Pripremiti tekstualne podatke za analizu, uključujući njihovo čišćenje i transformaciju u format pogodan za daljnju obradu.\n",
        "- Izvesti analizu vrsta riječi u tekstu i interpretirati statistike, poput broja imenica, glagola ili pridjeva, te razumjeti kakve informacije to daje o stilu i sadržaju teksta.\n",
        "- Usporediti rezultate dobivene različitim alatima (`spaCy` vs `NLTK`) i razumjeti prednosti i ograničenja svakog pristupa.\n",
        "- Steći temelj za naprednije NLP zadatke, kao što su analiza sentimenta (prepoznavanje tona u jeziku), prepoznavanje entiteta ili parsiranje rečenica.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYEKluwlA19c"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeA9etoA0OT"
      },
      "source": [
        "## Instalacija potrebnih biblioteka\n",
        "\n",
        "Koristit ćemo `spaCy` i `NLTK`, dvije najčešće korištene NLP biblioteke u Pythonu.\n",
        "\n",
        "Web stranice:\n",
        "- [Spacy 101](https://spacy.io/usage/spacy-101)\n",
        "- [NTLK](https://www.nltk.org/)\n",
        "\n",
        "`spaCy` ima unaprijed trenirane modele za različite jezike, što znači da odmah možete obraditi tekstove bez dodatnog treniranja vlastitih modela. Njegovi modeli uključuju sve od tokenizacije, lematizacije i POS tagiranja, do naprednijih funkcionalnosti poput prepoznavanja entiteta (NER) i parsiranja rečenica. spaCy je optimiziran za brzinu i praktičnu primjenu, pa se često koristi u industriji i istraživačkim projektima gdje su važni performanse i preciznost.\n",
        "\n",
        "S druge strane, `NLTK` je prvenstveno edukacijski alat koji služi kao uvod u obradu prirodnog jezika i osnovne algoritme. Pruža veliki broj klasičnih metoda i korpusa, uključujući tokenizaciju, stemming, lematizaciju, POS tagiranje i različite tekstualne korpuse za eksperimentiranje. NLTK je vrlo pogodan za učenje i razumijevanje principa NLP-a, ali za stvarne produkcijske zadatke često je sporiji i manje precizan u odnosu na spaCy, posebno na velikim količinama podataka.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:28.190557Z",
          "start_time": "2025-10-27T19:30:21.394786Z"
        },
        "id": "xYQCTV5P6q-h"
      },
      "outputs": [],
      "source": [
        "# dependencies\n",
        "!pip install -q -U spacy nltk matplotlib\n",
        "\n",
        "# small English language model for spaCy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:28.211243Z",
          "start_time": "2025-10-27T19:30:28.208605Z"
        },
        "id": "ud44db-z7B4k"
      },
      "outputs": [],
      "source": [
        "import nltk, spacy\n",
        "print(\"spaCy version:\", spacy.__version__)\n",
        "print(\"NLTK version:\", nltk.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:30.537391Z",
          "start_time": "2025-10-27T19:30:28.226293Z"
        },
        "id": "G6TTYso2-F_C"
      },
      "outputs": [],
      "source": [
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC7qrjqZByvF"
      },
      "source": [
        "## Što je NLP?\n",
        "NLP (Natural Language Processing) je područje umjetne inteligencije koje se bavi razumijevanjem, obradom i generiranjem ljudskog jezika pomoću računala.\n",
        "\n",
        "## Ključni koraci obrade teksta:\n",
        "1. **Čišćenje i normalizacija teksta** – uklanjanje nepotrebnih znakova, brojeva, simbola.\n",
        "2. **Tokenizacija** – razbijanje teksta na manje jedinice (tokene).\n",
        "3. **Uklanjanje stop-riječi** – riječi bez informacijske vrijednosti (npr. \"and\", \"the\", \"is\").\n",
        "4. **Lematizacija** – pretvaranje riječi u osnovni oblik (npr. \"running\" u \"run\").\n",
        "5. **POS tagging** – označavanje svake riječi prema gramatičkoj kategoriji (imenica, glagol, pridjev...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJfPVpC-CM0k"
      },
      "source": [
        "## Učitavanje uzorka teksta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:30.892451Z",
          "start_time": "2025-10-27T19:30:30.549733Z"
        },
        "id": "7jwWCmpbCcTq"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"\"\"Artificial intelligence is transforming industries across the world.\n",
        "It enables machines to learn from data, recognize patterns, and make decisions\n",
        "with minimal human intervention. However, ethical concerns continue to grow.\"\"\"\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4Ni0GwkCwVF"
      },
      "source": [
        "## Tokenizacija, lematizacija i POS tagging u spaCy biblioteci\n",
        "\n",
        "POS (Part-of-Speech) tagging je proces dodjeljivanja gramatičke oznake svakoj riječi.  \n",
        "Primjeri oznaka:\n",
        "- NOUN – imenica\n",
        "- VERB – glagol\n",
        "- ADJ – pridjev\n",
        "- ADV – prilog\n",
        "- PRON – zamjenica\n",
        "\n",
        "U spaCy-ju svaka riječ ima dvije oznake:\n",
        "- `pos_`: šira gramatička kategorija, vrsta riječi\n",
        "- `tag_`: detaljna oznaka prema Penn Treebank standardu\n",
        "\n",
        "Primijetite da spaCy automatski radi POS tagging prilikom obrade teksta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:30.906285Z",
          "start_time": "2025-10-27T19:30:30.902968Z"
        },
        "id": "jMdpBJ_i9lOP"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(f\"{token.text:<15} | {token.lemma_:<15} | {token.pos_:<15} | {token.tag_:<10} | {token.is_stop}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vite2s8lL_nT"
      },
      "source": [
        "## Razlika između *stemming*-a i lematizacije\n",
        "\n",
        "U ovom primjeru vidjet ćete razliku između **stemminga** i **lematizacije** koristeći NLTK i spaCy.  \n",
        "Primijetit ćete da stemming ponekad daje neprirodne oblike riječi, dok lematizacija vraća gramatički ispravne osnovne oblike.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:31.247235Z",
          "start_time": "2025-10-27T19:30:30.919230Z"
        },
        "id": "XPdZJs_VMNcZ"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# primjer\n",
        "words = [\"running\", \"studies\", \"better\", \"cars\", \"went\", \"flying\"]\n",
        "\n",
        "# Stemming pomoću NLTK PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "# Lematizacija pomoću NLTK WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words_nltk = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "# Lematizacija pomoću spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\" \".join(words))\n",
        "lemmatized_words_spacy = [token.lemma_ for token in doc]\n",
        "\n",
        "print(\"Originalne riječi:     \", words)\n",
        "print(\"Stemming (NLTK):       \", stemmed_words)\n",
        "print(\"Lematizacija (NLTK):   \", lemmatized_words_nltk)\n",
        "print(\"Lematizacija (spaCy):  \", lemmatized_words_spacy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB-Neq0ADhfG"
      },
      "source": [
        "## Filtriranje tokena\n",
        "\n",
        "Sada ćemo iz početnog teksta ukloniti:\n",
        "- stop-riječi (poput \"is\", \"the\", \"to\")\n",
        "- interpunkciju\n",
        "- brojeve\n",
        "\n",
        "Ostat će samo lematizirani, čisti tokeni koji nose semantičku vrijednost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:31.262728Z",
          "start_time": "2025-10-27T19:30:31.259902Z"
        },
        "id": "gBZmlZOeDgOr"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "clean_tokens = [token.lemma_.lower() for token in doc\n",
        "                if not token.is_stop and token.is_alpha]\n",
        "\n",
        "print(clean_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogVR6D6bG6Zw"
      },
      "source": [
        "## Statistička analiza POS oznaka\n",
        "\n",
        "Možemo analizirati koliko ima imenica, glagola, pridjeva itd.  \n",
        "Takva statistika daje uvid u strukturu teksta – primjerice, tehnički tekst ima više imenica i manje pridjeva.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:31.352763Z",
          "start_time": "2025-10-27T19:30:31.276855Z"
        },
        "id": "CVCWhmzS-IjP"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pos_counts = Counter([token.pos_ for token in doc])\n",
        "print(pos_counts)\n",
        "\n",
        "plt.barh(pos_counts.keys(), pos_counts.values())\n",
        "plt.title(\"Distribucija vrsta riječi (POS tags)\")\n",
        "plt.ylabel(\"Vrsta riječi\")\n",
        "plt.xlabel(\"Broj pojavljivanja\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdh3lRDcG_e-"
      },
      "source": [
        "## Usporedba sa NLTK\n",
        "\n",
        "Biblioteka **NLTK (Natural Language Toolkit)** bila je jedan od prvih ozbiljnih alata za rad s prirodnim jezikom u Pythonu i dugo je služila kao standard u akademskim okruženjima.  \n",
        "NLTK ima vlastitu implementaciju POS taggera koja koristi **Penn Treebank oznake** – to je skup standardiziranih kratkih oznaka (npr. `NN` za imenice, `VB` za glagole, `JJ` za pridjeve). Ove oznake potječu iz jednog od najpoznatijih lingvističkih korpusa na engleskom jeziku.\n",
        "\n",
        "U ovoj vježbi koristimo NLTK-ov ugrađeni tagger `averaged_perceptron_tagger`, koji se temelji na statističkoj metodi perceptrona i radi vrlo brzo, ali nije uvijek dosljedan u svim kontekstima. Za kraće tekstove je sasvim dovoljan.\n",
        "\n",
        "Kad usporedite rezultate **spaCyja** i **NLTK-a**, primijetit ćete da se oznake ponekad ne poklapaju. To je posljedica nekoliko razlika u načinu rada ovih alata:\n",
        "\n",
        "- **Tokenizacija**: spaCy koristi vlastiti tokenizator koji prepoznaje skraćenice, brojeve i interpunkciju inteligentnije od NLTK-ovog osnovnog tokenizatora.  \n",
        "- **Modeli**: spaCy koristi unaprijed trenirani model temeljen na modernijim metodama (npr. kontekstualni vektori i neuronske mreže), dok NLTK koristi starije, *rule-based* i statističke pristupe.  \n",
        "- **Oznake i korpusi**: iako se oba oslanjaju na Penn Treebank sustav, implementacije se razlikuju jer su modeli trenirani na različitim verzijama i podskupovima korpusa.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:31.379106Z",
          "start_time": "2025-10-27T19:30:31.365494Z"
        },
        "id": "YqtqGlh5HBmg"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "nltk_tags = pos_tag(tokens)\n",
        "\n",
        "# spaCy\n",
        "spacy_tags = [(token.text, token.pos_) for token in doc]\n",
        "\n",
        "print(\"Usporedba NLTK i spaCy tagova:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Word':<15} | {'NLTK Tag':<10} | {'spaCy Tag':<10}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Primijetite da se tagovi ponekad razlikuju ovisno o tome koju biblioteku koristimo\n",
        "spacy_tag_dict = {token.text: token.tag_ for token in doc}\n",
        "\n",
        "for word, nltk_tag in nltk_tags:\n",
        "    spacy_tag = spacy_tag_dict.get(word, \"N/A\")\n",
        "    print(f\"{word:<15} | {nltk_tag:<10} | {spacy_tag:<10}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-bzwmXBTmtV"
      },
      "source": [
        "### Primijetite da je NLTK prepoznao riječ 'recognize' kao imenicu, dok je spaCy prepoznao da je to glagol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x10MYkpzV1KR"
      },
      "source": [
        "## Pomoćne funkcije za zadatke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:31.397941Z",
          "start_time": "2025-10-27T19:30:31.394335Z"
        },
        "id": "uYFAy-RAV1KR"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "\n",
        "def fetch_html(url, filename):\n",
        "    response = requests.get(url)\n",
        "    response.encoding = 'utf-8'\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(response.text)\n",
        "    return response.text\n",
        "\n",
        "def load_html(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "def strip_tags(text):\n",
        "    return re.sub('<[^<]+?>', '', text).strip()\n",
        "\n",
        "def clean_and_split(text):\n",
        "    text = re.sub(r'>(\\s*)<', '> <', text)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50YBKol-OU5D"
      },
      "source": [
        "## Zadatak 1\n",
        "\n",
        "Preuzmi HTML sadržaj s poveznice [https://www.coursera.org/articles/natural-language-processing](https://www.coursera.org/articles/natural-language-processing) koristeći Python biblioteku `requests`. Zatim, pomoću regularnih izraza (*regex*-a), pronađi i prebroji koliko puta se pojavljuju riječi **NLP** i fraza **natural language** (ignoriraj velika/mala slova). Prebroji koliko puta se u tekstu pojavljuju HTML tagovi `<h1>`, `<h2>`, `<h3>` i `<p>`. Na kraju, pronađi i prebroji koliko eksternih referenci postoji tako da izvučeš sve linkove (https://...). Sve rezultate ispiši na ekranu. Pomoćne funkcije nalaze se u ćeliji iznad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:31.909229Z",
          "start_time": "2025-10-27T19:30:31.410972Z"
        },
        "id": "A9YI48uDOrF1"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.coursera.org/articles/natural-language-processing\"\n",
        "filename = \"article.html\"\n",
        "\n",
        "# Dohvaćanje HTMLa sa stranice i spremi na disk\n",
        "html = fetch_html(url, filename)\n",
        "\n",
        "# Parsiranje HTMLa regularnim izrazima za tražene pojmove/tipove tagova\n",
        "nlp_count = len(re.findall(r'\\bNLP\\b', html, re.IGNORECASE))\n",
        "natural_language_count = len(re.findall(r'natural language', html, re.IGNORECASE))\n",
        "\n",
        "h1_count = len(re.findall(r'<h1', html, re.IGNORECASE))\n",
        "h2_count = len(re.findall(r'<h2', html, re.IGNORECASE))\n",
        "h3_count = len(re.findall(r'<h3', html, re.IGNORECASE))\n",
        "p_count  = len(re.findall(r'<p',  html, re.IGNORECASE))\n",
        "\n",
        "external_links_count = len(re.findall(r'href=[\\'\"]https', html))\n",
        "\n",
        "# Ispis rezultata na ekranu\n",
        "print(f\"Broj pojavljivanja 'NLP': {nlp_count}\")\n",
        "print(f\"Broj pojavljivanja 'natural language': {natural_language_count}\")\n",
        "print(f\"Broj <h1> tagova: {h1_count}\")\n",
        "print(f\"Broj <h2> tagova: {h2_count}\")\n",
        "print(f\"Broj <h3> tagova: {h3_count}\")\n",
        "print(f\"Broj <p> tagova: {p_count}\")\n",
        "print(f\"Broj eksternih linkova: {external_links_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWT0U12fOXHi"
      },
      "source": [
        "## Zadatak 2\n",
        "\n",
        "Učitaj HTML sadržaj članka koji si prethodno preuzeo (ili koristi istu tekstualnu varijablu). Uz pomoć custom funkcija za parsiranje i čišćenje teksta, izdvoji glavni naslov članka (element `<h1>`), sve podnaslove (`<h2>` i `<h3>`) te tekst iz svih paragrafa (`<p>`). Paragrafe spoji u jedan cjeloviti string tako da koristiš novi red kao separator i ispiši prvih 500 znakova rezultirajućeg teksta. Pronađi i ispiši prvih pet stavki nabrajanja (element `<li>`), ako postoje. Sve tražene podatke ispiši na ekranu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:31.934904Z",
          "start_time": "2025-10-27T19:30:31.923036Z"
        },
        "id": "wi7uBRpOOrfR"
      },
      "outputs": [],
      "source": [
        "filename = \"article.html\"\n",
        "html = load_html(filename)\n",
        "\n",
        "# Glavni naslov <h1>\n",
        "main_title = re.search(r'<h1.*?>(.*?)</h1>', html, re.DOTALL | re.IGNORECASE)\n",
        "print(\"Glavni naslov:\", strip_tags(main_title.group(1)) if main_title else \"Nema\")\n",
        "\n",
        "# Podnaslovi <h2> i <h3>\n",
        "h2s = [strip_tags(x) for x in re.findall(r'<h2.*?>(.*?)</h2>', html, re.DOTALL | re.IGNORECASE) if strip_tags(x)]\n",
        "h3s = [strip_tags(x) for x in re.findall(r'<h3.*?>(.*?)</h3>', html, re.DOTALL | re.IGNORECASE) if strip_tags(x)]\n",
        "print(\"Podnaslovi (h2):\", h2s)\n",
        "print(\"Podnaslovi (h3):\", h3s)\n",
        "\n",
        "# Paragrafski tekst <p>\n",
        "paragraphs = re.findall(r'<p.*?>(.*?)</p>', html, re.DOTALL | re.IGNORECASE)\n",
        "full_text = '\\n'.join([clean_and_split(p) for p in paragraphs if clean_and_split(p)])\n",
        "print(\"Prvih 500 znakova teksta:\", full_text[:500])\n",
        "\n",
        "# Nabrajanja (li): samo prave <li> tagove\n",
        "li_items = re.findall(r'<li(?:\\s|>)[^>]*>(.*?)</li>', html, re.DOTALL | re.IGNORECASE)\n",
        "if li_items:\n",
        "    print(\"Nabrojane stavke (li):\")\n",
        "    for item in li_items[:5]:\n",
        "        print(\"-\", strip_tags(item))\n",
        "else:\n",
        "    print(\"Nema nabrajanja u članku.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j1Wc4HROX3H"
      },
      "source": [
        "## Zadatak 3\n",
        "\n",
        "Analiziraj tekst članka s pomoću `spaCy` biblioteke. Filtriraj tokene (bez stopwords, interpunkcije i praznih), prikaži tablicu za prvih 30 tokena (riječ, lema, POS), ispiši broj svih riječi, jedinstvenih riječi i rečenica. Prikaži tri najčešća POS taga i nacrtaj bar chart njihovih frekvencija. Koristi definirane funkcije za dohvat i čišćenje teksta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:32.607971Z",
          "start_time": "2025-10-27T19:30:31.946362Z"
        },
        "id": "LXY-mWv1Orxa"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filename = \"article.html\"\n",
        "html = load_html(filename)\n",
        "\n",
        "paragraphs = re.findall(r'<p.*?>(.*?)</p>', html, re.DOTALL | re.IGNORECASE)\n",
        "full_text = '\\n'.join([clean_and_split(p) for p in paragraphs if clean_and_split(p)])\n",
        "\n",
        "# NLP analiza sa spaCy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(full_text)\n",
        "\n",
        "# Filtrirani tokeni (bez stopwords, interpunkcije, praznih)\n",
        "tokens = [token for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
        "\n",
        "# Tablica za prvih 30 tokena\n",
        "print(f\"{'Riječ':15} {'Lema':15} {'POS':8}\")\n",
        "for token in tokens[:30]:\n",
        "    print(f\"{token.text:15} {token.lemma_:15} {token.pos_:8}\")\n",
        "\n",
        "num_words = len([token for token in doc if not token.is_punct and not token.is_space])\n",
        "num_unique_words = len(set(token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space))\n",
        "num_sentences = len(list(doc.sents))\n",
        "print(\"\\nBroj riječi:\", num_words)\n",
        "print(\"Broj jedinstvenih riječi:\", num_unique_words)\n",
        "print(\"Broj rečenica:\", num_sentences)\n",
        "\n",
        "# Tri najčešća POS taga\n",
        "pos_counts = Counter(token.pos_ for token in tokens)\n",
        "print(\"\\nTri najčešća POS taga:\")\n",
        "for pos, count in pos_counts.most_common(3):\n",
        "    print(f\"{pos}: {count}\")\n",
        "\n",
        "# Bar chart POS tagova\n",
        "labels, values = zip(*pos_counts.items())\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(labels, values)\n",
        "plt.title(\"Frekvencija POS tagova\")\n",
        "plt.ylabel(\"Broj pojavljivanja\")\n",
        "plt.xlabel(\"POS tag\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PAjKyS5J8yG"
      },
      "source": [
        "## Opcionalno: POS tagging na hrvatskom jeziku\n",
        "spaCy podržava hrvatski model `hr_core_news_sm`.\n",
        "\n",
        "Usporedite dosadašnje rezultate s engleskim tekstom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-10-27T19:30:37.650346Z",
          "start_time": "2025-10-27T19:30:32.621513Z"
        },
        "id": "JbhZUBnLJ-Jr"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download hr_core_news_sm\n",
        "import spacy\n",
        "nlp_hr = spacy.load(\"hr_core_news_sm\")\n",
        "\n",
        "text_hr = \"Umjetna inteligencija mijenja način na koji živimo i radimo.\"\n",
        "doc_hr = nlp_hr(text_hr)\n",
        "\n",
        "for token in doc_hr:\n",
        "    print(f\"{token.text:<15} | lemma: {token.lemma_:<15} | POS: {token.pos_:<10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVt2GFjoJ6yw"
      },
      "source": [
        "## Zaključak\n",
        "\n",
        "U ovoj vježbi ste naučili kako se tekst može pripremiti za analizu, odnosno kako ga **normalizirati**, očistiti od nepotrebnih znakova i stop-riječi, te pretvoriti u oblik pogodan za daljnju obradu. Također ste primijenili **POS tagging** pomoću biblioteka spaCy i NLTK i vidjeli kako se svaka riječ može označiti odgovarajućom gramatičkom kategorijom. Na kraju ste naučili **interpretirati rezultate** i dobili uvid u strukturu jezika u tekstu, primjerice, koje vrste riječi prevladavaju i što to govori o stilu i sadržaju teksta.\n",
        "\n",
        "### Što dalje?\n",
        "- Analizirajte tekstove različitih domena (npr. vijesti vs. književnost, tehnički tekstovi vs. blogovi) i usporedite njihove POS distribucije kako biste uočili stilističke i sadržajne razlike.\n",
        "- Napravite **grafičku usporedbu više dokumenata** s obzirom na njihovu POS strukturu, što može pomoći u vizualizaciji dominantnih vrsta riječi i razlikovanju tipova tekstova.\n",
        "- Istražite razlike između modela za različite jezike ili različite alate za POS tagging kako biste razumjeli kako izbor tehnologije utječe na analizu.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
